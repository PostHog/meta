# RFC - Test Pipeline Changes on Real Customer Data w/o Affecting Actual Prod Data

## Background
We now have reasonable traction with our data warehouse product and the cost of making breaking changes with
incremental updates is growing as we accrue more and more external sources, self-managed sources, and saved queries each
day. At this time, we don't have enough confidence in our (mostly unit) test suite and development workloads don't
closely mimic the realities of production scenarios. Not all the sources have similar distributions of use, but one
common theme is that many are SQL based and our data eventually end up in s3 via delta tables and are queryable via
HogQl, so that feels like the area to hone our focus on for biggest impact. Other data sources like HubSpot, Salesforce,
and Chargebee are less generic and also would have a smaller blast radius in the event syncing incremental or full table
syncing gets regressed. These sources are still important and should be incorporated into the test plan as it matures.

## Higher Level Goals
- Determinism - We do not want to randomly sample sources/schemas in order to test against. This list of tests should
  grow over time, but remain consistent for feature development.
- Repeatability - A failure one run should fail the same way the next run, A success should also be repeatable.
- Not Ignorable - A scheduled out of band test can and will be ignored, so this test sequence should run as part of CI.
- Uses "real" data - Not anchored to "test" datasets that fail to capture the madness of the real world.
- No Perf Degradation - We don't wish to interfere with any production workloads or queries.
- No Cost/CPU Impact - We don’t wish to run any out of band testing workloads that would impact a live service, with the
  possible exception of testing our own services that are in the purview of PostHog.

## Types of Actions to Test
- Syncs
    - Incremental
    - Full table
- HogQl queries (joins)

> Preface: The main idea behind this strategy is to reverse the direction of our standard syncing procedure in order to
> determine if we can reconstruct our block storage data (delta → s3) back into the original data store it came from (
> Postgres, MySql, etc…), and query it once it’s reconstructed as before once it has been put back together.

> Note: The diagram below can be used as an aide.

## Steps
1. The first step would be to transfer data from a configurable list of sub-buckets under
   `posthog-s3-datawarehouse-us-east-1` into an ephemeral s3 bucket from a list of deltalake tables from prod → dev
   environment. Using this approach we can avoid looking at credentials and our Postgres instance. This also means that
   we have very minimal interactions with production as a whole.

2. Reconstruct stateful instances from the delta tables in our CI flow. This would require different processes for
   various providers. For example, for MySql we could take an official image, deploy it with ArgoCD, then have a program
   move the data that has been temporarily copied into our dev s3 bucket into entities we consider external data
   sources.

3. Run an on demand temporal workflow to test our standard syncing operation as if it’s any other production workflow.

4. The results of these workflows will end up back in s3 via delta as an output. We should be able to run queries at
   this point.

5. Compare the results of the original copied s3 payloads to the s3 payloads that went through the temporal processor
   and were synced. This is mostly a parity check to ensure that our syncing process is working as expected.

6. Run test case queries on data that has moved from s3 → external_data_source → s3 either with custom queries or test
   queries inherited from production.

7. Reverse of #1 to clean up all fragments of delta tables that have been copied into the dev environment and buckets
   that have. Cleanup fragments in Clickhouse that have been generated by this process as well.

[Data Warehouse Testing Production Flow](./images/dw-testing-production-flo.png)

## Out of Scope
- Temporal Scheduling Logic - We want to ensure that sync works, not that temporal invokes a schedule at the correct
  interval.
- Load testing - For massive queries that exceed thresholds encountered in production. This is mostly meant to test if
  the schemas and queries for syncs are working, not if we can handle massive transactions.

## Tooling
- ArgoCd
    - Source containers (Postgres, MySql, Snowflake)
    - Source destinations (Postgres, MySql, Snowflake)
    - Clickhouse (Reuse in dev environment as query layer)
    - Temporal Runner(Reuse in dev environment as query layer)
- S3
- GitHub Actions (Invoke when changing subset of our directories, triggering agent)

## Concerns/Open Questions
- How feasible is it to recreate instances of more hosted type databases, like Snowflake, would something like
  LocalStack be an option for us?
- It is too much work to do this for some many of our integrations, would we become test automation specialists instead
  of software engineers? How can we maintain this balance over time added more and more source types?
- What would be the best way to simulate other sources like Salesforce?
- Should we use a test account for something like Stripe?
- Would we like to test out complicated joins on queries between multiple sources and events? 





